import type { ListenApiList } from "../../stores/useListenApi";

export type ListenApi = (callback?: (text: string) => void) => {
  result: Promise<string>;
  start: () => void;
  stop: () => void;
};
export type ListenApiTest = () => Promise<boolean>;

const SpeechRecognition =
  // @ts-expect-error TS æ— æ³•è¯†åˆ« Web Speech API
  window.SpeechRecognition || window.webkitSpeechRecognition;

const listen_browser: ListenApi = (callback) => {
  const recognition = new SpeechRecognition();
  recognition.lang = "zh-CN";
  recognition.interimResults = true; // å¯ç”¨ä¸´æ—¶ç»“æœï¼Œè·å¾—æ›´å¥½çš„è¿ç»­æ€§
  recognition.continuous = true; // å¯ç”¨è¿ç»­è¯†åˆ«ï¼Œé¿å…è‡ªåŠ¨åœæ­¢
  recognition.maxAlternatives = 1;

  const { promise, resolve, reject } = Promise.withResolvers<string>();
  let finalTranscript = "";
  let recognizing = false;
  let silenceTimer: NodeJS.Timeout | null = null;
  let lastSpeechTime = Date.now();

  // æ£€æµ‹é™éŸ³çš„å‡½æ•°
  const checkSilence = () => {
    const now = Date.now();
    const silenceDuration = now - lastSpeechTime;

    // å¦‚æœé™éŸ³è¶…è¿‡2ç§’ä¸”æœ‰æœ€ç»ˆç»“æœï¼Œåˆ™åœæ­¢è¯†åˆ«
    if (silenceDuration > 2000 && finalTranscript.trim()) {
      console.log("ğŸ”‡ æ£€æµ‹åˆ°é™éŸ³ï¼Œåœæ­¢è¯†åˆ«");
      if (recognizing) {
        recognition.stop();
      }
    }
  };

  // @ts-expect-error TS æ— æ³•è¯†åˆ« Web Speech API
  recognition.onstart = () => {
    recognizing = true;
    lastSpeechTime = Date.now();
    console.log("ğŸ¤ è¯­éŸ³è¯†åˆ«å¼€å§‹è†å¬...");
  };

  // @ts-expect-error TS æ— æ³•è¯†åˆ« Web Speech API
  recognition.onend = () => {
    recognizing = false;
    if (silenceTimer) {
      clearInterval(silenceTimer);
      silenceTimer = null;
    }
    console.log("âœ… è¯­éŸ³è¯†åˆ«å®Œæˆï¼Œæœ€ç»ˆç»“æœ:", finalTranscript);
    resolve(finalTranscript || "æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹");
  };

  // @ts-expect-error TS æ— æ³•è¯†åˆ« Web Speech API
  recognition.onerror = (event) => {
    recognizing = false;
    if (silenceTimer) {
      clearInterval(silenceTimer);
      silenceTimer = null;
    }
    console.error("âš ï¸ è¯­éŸ³è¯†åˆ«é”™è¯¯:", event.error);

    // å¦‚æœæ˜¯å› ä¸ºæ²¡æœ‰è¯­éŸ³è¾“å…¥è€Œåœæ­¢ï¼Œè¿”å›å·²æœ‰ç»“æœ
    if (event.error === "no-speech" && finalTranscript.trim()) {
      resolve(finalTranscript);
    } else {
      reject(new Error(`è¯­éŸ³è¯†åˆ«é”™è¯¯: ${event.error}`));
    }
  };

  // @ts-expect-error TS æ— æ³•è¯†åˆ« Web Speech API
  recognition.onresult = (event) => {
    let interimTranscript = "";
    let newFinalTranscript = "";

    for (let i = event.resultIndex; i < event.results.length; ++i) {
      const transcript = event.results[i][0].transcript;
      if (event.results[i].isFinal) {
        newFinalTranscript += transcript;
      } else {
        interimTranscript += transcript;
      }
    }

    // æ›´æ–°æœ€åè¯´è¯æ—¶é—´
    if (newFinalTranscript || interimTranscript) {
      lastSpeechTime = Date.now();
    }

    // æ›´æ–°æœ€ç»ˆç»“æœ
    if (newFinalTranscript) {
      finalTranscript += newFinalTranscript;
      console.log("ğŸ“ æœ€ç»ˆè¯†åˆ«ç»“æœ:", newFinalTranscript);
    }

    // å®æ—¶å›è°ƒï¼ˆåŒ…å«ä¸´æ—¶ç»“æœï¼‰
    const currentResult = finalTranscript + interimTranscript;
    if (typeof callback === "function" && currentResult.trim()) {
      callback(currentResult);
    }

    // å¯åŠ¨é™éŸ³æ£€æµ‹
    if (!silenceTimer && recognizing) {
      silenceTimer = setInterval(checkSilence, 500);
    }
  };

  return {
    result: promise,
    start: () => {
      if (!recognizing) {
        lastSpeechTime = Date.now();
        recognition.start();
      }
    },
    stop: () => {
      if (recognizing) {
        recognition.stop();
      }
      if (silenceTimer) {
        clearInterval(silenceTimer);
        silenceTimer = null;
      }
    },
  };
};

const test_browser: ListenApiTest = async () => {
  try {
    if (!SpeechRecognition) {
      throw new Error("å½“å‰æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«ï¼Œè¯·ä½¿ç”¨ Chrome/Edge æ¡Œé¢ç‰ˆ");
    }
    if (sessionStorage.getItem("microphone_tested") === "pass") {
      return true;
    }
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    for (const track of stream.getTracks()) {
      track.stop();
    }
    sessionStorage.setItem("microphone_tested", "pass");
    return true;
  } catch (e) {
    throw new Error(`è¯­éŸ³è¯†åˆ«æµ‹è¯•å¤±è´¥: ${e instanceof Error ? e.message : e}`);
  }
};

export const listenApiList: ListenApiList = [
  {
    name: "æµè§ˆå™¨è¯­éŸ³è¯†åˆ«",
    api: () => ({
      api: (callback: (text: string) => void) => listen_browser(callback),
      test: () => test_browser(),
    }),
  },
];
